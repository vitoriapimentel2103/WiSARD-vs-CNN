üß† Projeto de Compara√ß√£o entre WiSARD e CNN no Reconhecimento de D√≠gitos Manuscritos (MNIST)
Esse projeto foi desenvolvido por mim, Maria Vit√≥ria Pimentel Ara√∫jo, como um experimento comparativo entre dois modelos de classifica√ß√£o bem diferentes: uma rede WiSARD (baseada em mem√≥ria RAM) e uma CNN (rede neural convolucional cl√°ssica) para reconhecer d√≠gitos do dataset MNIST.

üß© Pr√©-processamento
Primeiro, eu carreguei o dataset MNIST usando o Keras. O MNIST √© composto por imagens 28x28 de d√≠gitos escritos √† m√£o. Para treinar o WiSARD, transformei essas imagens em bin√°rias, comparando cada pixel com o valor 127 (ou seja, se o pixel for maior que 127, ele vira 1, sen√£o vira 0). Depois, achatei cada imagem 28x28 pra um vetor de 784 posi√ß√µes. Tamb√©m mostrei uma amostrinha visual com matplotlib s√≥ pra ter certeza de que estava tudo certo com os dados.

üß† Implementando o WiSARD
Implementei uma classe Discriminator, que funciona como o c√©rebro da rede WiSARD. Cada discriminador √© respons√°vel por aprender a reconhecer um d√≠gito espec√≠fico (0 a 9). A entrada bin√°ria √© dividida em v√°rios endere√ßos menores (RAMs), que guardam os padr√µes que aparecem durante o treino. Usei um embaralhamento aleat√≥rio fixo pra criar o mapeamento (chamado de shared mapping), o que ajuda a garantir que todos os discriminadores usem os mesmos padr√µes de divis√£o dos dados.

‚öôÔ∏è Treinamento do WiSARD
Criei 10 discriminadores (um pra cada classe de d√≠gito) e treinei cada um apenas com as imagens da sua respectiva classe. O treino √© super r√°pido, porque o WiSARD basicamente s√≥ conta quantas vezes cada padr√£o aparece.

üîç Predi√ß√£o com WiSARD
Na hora de testar, pra cada imagem eu passo por todos os discriminadores e vejo qual responde melhor (ou seja, qual RAM tem mais padr√µes que batem com a entrada). Implementei um sistema de bleaching, que resolve empates tentando ir diminuindo o n√≠vel de exig√™ncia at√© sobrar s√≥ um candidato. No final, calculei a acur√°cia do WiSARD no conjunto de teste e o tempo total de infer√™ncia.

üß† Implementando a CNN
Pra comparar com um modelo mais tradicional e robusto, tamb√©m treinei uma CNN simples usando PyTorch. Ela tem duas camadas convolucionais + pooling, depois duas camadas totalmente conectadas. Usei ReLU como fun√ß√£o de ativa√ß√£o e Adam como otimizador. O treino foi feito por 3 √©pocas com batch size de 64, e os dados foram normalizados automaticamente com ToTensor().

üìä Compara√ß√£o entre modelos
Ao final, comparei os dois modelos tanto em tempo de treinamento quanto em acur√°cia. A CNN, como esperado, tem uma acur√°cia bem maior ‚Äî mas tamb√©m √© bem mais pesada pra treinar. J√° o WiSARD √© super leve e r√°pido, o que pode ser uma vantagem dependendo do contexto. A ideia aqui n√£o √© dizer qual √© "melhor", mas mostrar como diferentes abordagens funcionam pra o mesmo problema.
